# 3 线性神经网络

## 3.4 softmax回归

[一文详解Softmax函数](https://zhuanlan.zhihu.com/p/105722023)

## 3.5 Fashion-MNIST图像分类数据集

通过 ``from torchvision import transforms`` 导入的框架内置函数将Fashion-MNIST数据集下载并读取到内存中

## 3.6 softmax从零开始实现

``` python
y = torch.tensor([0, 2])
y_hat = torch.tensor([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]])
y_hat[[0, 1], y]
```

这里假定0代表苹果，1代表橘子，2代表香蕉，y=[0,2]0代表第一个图片真的是苹果，2代表第二个图片真的是香蕉。

y_hat是预测值，里头存的是预测的概率，那么y_hat里头两列，表示算法识别第一个图片是苹果的概率是0.1，是橘子的概率为0.3，是香蕉的概率是0.6.第二个图片类似。y_hat[[0,1]，y]=[0.1][0.5]意思就是，这个算法把第一个图片识别为苹果的概率是0.1，第二个图片识别成香蕉的概率是0.5。————即，我这个调教出来的算法，识别正确的概率。

[可做参考的知乎回答](https://www.zhihu.com/question/23765351/answer/2144591565)

``` python
def cross_entropy(y_hat, y):
    return -torch.log(y_hat[range(len(y_hat)), y])
```

这里定义的交叉熵就是利用y的独热编码(One-hot Encoding)取出真实概率，在进行取-log

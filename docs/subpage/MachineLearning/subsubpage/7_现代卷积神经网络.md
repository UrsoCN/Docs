# 7 现代卷积神经网络

## 7.1 深度卷积神经网络（AlexNet）

AlexNet相对于LeNet的改进有：

1. 丢弃法
2. Sigmoid->ReLu
3. MeanPooling->MaxPooling
4. 隐藏全连接层后加入了丢弃层
5. 数据增强（手动在数据里加噪音？防止过拟合）

> AlexNet在训练时增加了大量的图像增强数据，如翻转、裁切和变色。 这使得模型更健壮，更大的样本量有效地减少了过拟合。

丢弃法是用来做模型的控制，因为AlexNet模型更大了，所以采用丢弃法来做模型的正则；ReLu相对于Sigmoid来说，梯度更大，且ReLu在零点处的一阶导更好，可以支撑更深的模型；MaxPooling取的是最大值，使得输出的值更大，梯度更大，使训练起来更容易。

LeNet仍然可以认为是一个机器学习的模型，而AlexNet规模增加了有几十倍，量变引起了质变，观念从特征提取转移到了通过CNN学习特征上。前者特征提取和网络是独立的，需要研究什么样的特征更适合网络模型，而后者分类器和特诊提取的模型是放在一起学习的。

> 2012年，AlexNet横空出世。它首次证明了学习到的特征可以超越手工设计的特征

![AlexNet](./images/AlexNet.png)

## 7.2 使用块的网络（VGG）


